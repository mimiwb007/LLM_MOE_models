{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gXelT0KGEwO"
      },
      "outputs": [],
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y pciutils\n",
        "!pip install langchain-ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!pip install ollama==0.4.2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama_serve():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "time.sleep(5)"
      ],
      "metadata": {
        "id": "Je-lYW3GGIMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull dbrx"
      ],
      "metadata": {
        "id": "DFR7SrbQGL4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "from IPython.display import Markdown\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = OllamaLLM(model=\"dbrx\")\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "# Prepare input for invocation\n",
        "input_data = {\n",
        "    \"question\": 'I have 2 apples, then I buy 2 more. I bake a pie with 2 of the apples. After eating half of the pie how many apples do I have left?'}\n",
        "\n",
        "# Invoke the chain with input data and display the response in Markdown format\n",
        "response = chain.invoke(input_data)\n",
        "display(Markdown(response))"
      ],
      "metadata": {
        "id": "Bqz3MskNGNIl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}